{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wngPtnEfb9u3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import numpy as np\n",
        "import seaborn\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVZlpw0zmUr4"
      },
      "outputs": [],
      "source": [
        "#!pip install faiss-cpu numpy langchain-openai langchain-community sentence_transformers typing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2HJkIh9hD5R",
        "outputId": "f10cb4d2-94f6-44d4-9baa-57b7e8bc91a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-13 14:09:40.962339: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import faiss\n",
        "import numpy as np\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from typing import List\n",
        "import re\n",
        "from datasets import Dataset\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfOWDYtjSvUs"
      },
      "outputs": [],
      "source": [
        "finetuning_dataset = pd.read_csv('rag_finetuning_questions_large.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyiazwkBSvUt",
        "outputId": "b6472e36-48ce-4978-cb90-11b9c7a5ae29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"EleutherAI/pythia-410m\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51MlWPXYSvUt"
      },
      "outputs": [],
      "source": [
        "embeddings_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pw1LBuWSvUt"
      },
      "outputs": [],
      "source": [
        "questions = finetuning_dataset[\"Questions\"]\n",
        "answers = finetuning_dataset[\"Answers\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xv3EUCLSvUt"
      },
      "outputs": [],
      "source": [
        "questions = [str(q) for q in finetuning_dataset[\"Questions\"] if pd.notna(q)]\n",
        "answers = [str(a) for a in finetuning_dataset[\"Answers\"] if pd.notna(a)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auWu2qQWSvUu"
      },
      "outputs": [],
      "source": [
        "formatted_texts = []\n",
        "for i in range(len(questions)):\n",
        "        text = f\"Question: {questions[i].strip()} Answer: {answers[i].strip()}\"\n",
        "        formatted_texts.append({\"text\": text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzI3_CvASvUu"
      },
      "outputs": [],
      "source": [
        "formatted_texts = pd.DataFrame(formatted_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3YZHv5YSvUu"
      },
      "outputs": [],
      "source": [
        "formatted_texts['labels'] = formatted_texts['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o74edn2SSvUu",
        "outputId": "004387a7-0bed-4c9d-d289-360bbd13e887"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Question: Q: What are the key differences betw...</td>\n",
              "      <td>Question: Q: What are the key differences betw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Question: Q: How does crop rotation benefit so...</td>\n",
              "      <td>Question: Q: How does crop rotation benefit so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Question: Q: Explain the Green Revolution's im...</td>\n",
              "      <td>Question: Q: Explain the Green Revolution's im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Question: Q: What are the primary differences ...</td>\n",
              "      <td>Question: Q: What are the primary differences ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Question: Q: How does the Doppler effect help ...</td>\n",
              "      <td>Question: Q: How does the Doppler effect help ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>Question: What is the significance of factorin...</td>\n",
              "      <td>Question: What is the significance of factorin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>Question: How does feedback regulation maintai...</td>\n",
              "      <td>Question: How does feedback regulation maintai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>Question: What is the principle behind electro...</td>\n",
              "      <td>Question: What is the principle behind electro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Question: How do hash tables optimize data ret...</td>\n",
              "      <td>Question: How do hash tables optimize data ret...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>Question: What is the relationship between pre...</td>\n",
              "      <td>Question: What is the relationship between pre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  \\\n",
              "0    Question: Q: What are the key differences betw...   \n",
              "1    Question: Q: How does crop rotation benefit so...   \n",
              "2    Question: Q: Explain the Green Revolution's im...   \n",
              "3    Question: Q: What are the primary differences ...   \n",
              "4    Question: Q: How does the Doppler effect help ...   \n",
              "..                                                 ...   \n",
              "145  Question: What is the significance of factorin...   \n",
              "146  Question: How does feedback regulation maintai...   \n",
              "147  Question: What is the principle behind electro...   \n",
              "148  Question: How do hash tables optimize data ret...   \n",
              "149  Question: What is the relationship between pre...   \n",
              "\n",
              "                                                labels  \n",
              "0    Question: Q: What are the key differences betw...  \n",
              "1    Question: Q: How does crop rotation benefit so...  \n",
              "2    Question: Q: Explain the Green Revolution's im...  \n",
              "3    Question: Q: What are the primary differences ...  \n",
              "4    Question: Q: How does the Doppler effect help ...  \n",
              "..                                                 ...  \n",
              "145  Question: What is the significance of factorin...  \n",
              "146  Question: How does feedback regulation maintai...  \n",
              "147  Question: What is the principle behind electro...  \n",
              "148  Question: How do hash tables optimize data ret...  \n",
              "149  Question: What is the relationship between pre...  \n",
              "\n",
              "[150 rows x 2 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatted_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiVRrx5JSvUu"
      },
      "outputs": [],
      "source": [
        "#finetuning_dataset = Dataset.from_pandas(formatted_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfR9ksgQSvUu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDoiK2rnSvUu"
      },
      "outputs": [],
      "source": [
        "#print(finetuning_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TxTyeLYSvUu"
      },
      "outputs": [],
      "source": [
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z23XdvvhSvUu"
      },
      "outputs": [],
      "source": [
        "text_tokenized = tokenizer(\n",
        "    formatted_texts['text'].tolist(),\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    max_length=700,\n",
        "    return_tensors='pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7arkroRSvUu"
      },
      "outputs": [],
      "source": [
        "text_tokenized['labels'] = text_tokenized['input_ids'].clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISr99SFkSvUv"
      },
      "outputs": [],
      "source": [
        "finetuning_dataset = Dataset.from_dict({\n",
        "    'input_ids': text_tokenized['input_ids'],\n",
        "    'attention_mask': text_tokenized['attention_mask'],\n",
        "    'labels': text_tokenized['labels']\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk76q4uOSvUv"
      },
      "outputs": [],
      "source": [
        "# text_tokenized = finetuning_dataset.map(\n",
        "#      lambda x: tokenizer(finetuning_dataset['text'], truncation=True, padding=\"max_length\", max_length=600, return_tensors=None),\n",
        "#      lambda x: tokenizer(finetuning_dataset['labels'], truncation=True, padding=\"max_length\", max_length=600, return_tensors=None),\n",
        "#      batched=True,\n",
        "#      remove_columns=finetuning_dataset.column_names\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfUA8z3BSvUv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OIenXl8SvUv",
        "outputId": "d2235098-b6b5-4d1e-8cfd-26b0b175d84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 150\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(finetuning_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwEYuUikSvUv"
      },
      "outputs": [],
      "source": [
        "finetuning_train_test = finetuning_dataset.train_test_split(test_size = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCkk9kEnSvUv",
        "outputId": "d64160d4-90b5-4440-b4eb-190e0b6f5614"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 105\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 45\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetuning_train_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62Lb2OFmSvUv"
      },
      "outputs": [],
      "source": [
        "finetune_train = finetuning_train_test['train']\n",
        "finetune_test = finetuning_train_test['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLETWOxlSvUv"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./rag_trainer_3\",\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=5e-5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_steps=100,\n",
        "    prediction_loss_only=True,\n",
        "    overwrite_output_dir = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtOs4oSmSvUv"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=finetune_train,\n",
        "    eval_dataset=finetune_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86nwLkgWSvUv",
        "outputId": "ad1c699d-6ac4-4057-90c9-b3f496006a03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 1:12:41, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.211066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.191953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=39, training_loss=0.3907907192523663, metrics={'train_runtime': 4456.9049, 'train_samples_per_second': 0.071, 'train_steps_per_second': 0.009, 'total_flos': 454732959744000.0, 'train_loss': 0.3907907192523663, 'epoch': 2.888888888888889})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhTCTQNjSvUv"
      },
      "outputs": [],
      "source": [
        "model = model.from_pretrained('./rag_trainer_3/checkpoint-7')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l75GMCPnSvUw"
      },
      "outputs": [],
      "source": [
        "simpletext_auto_documents = []\n",
        "for st_file in os.listdir('./simpletext_auto'):\n",
        "    text = open(f'/Users/davidlaszczkowski/Documents/4940_Grad_Project/simpletext_auto/{st_file}', \"r\")\n",
        "    read_text = text.read()\n",
        "    simpletext_auto_documents.append(read_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4cYkI9ySvUw"
      },
      "outputs": [],
      "source": [
        "chunked_documents = []\n",
        "for doc in simpletext_auto_documents:\n",
        "    sentences = re.split(r'(?<=[.!?]) +', doc)\n",
        "    i = 0\n",
        "    while i < (len(sentences)):\n",
        "        sentence_group = \" \".join(sentences[i:i+5])\n",
        "        chunked_documents.append(sentence_group)\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nr9iZt49h5BP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYFcTD0Onyq8"
      },
      "outputs": [],
      "source": [
        "embeddings_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJxJT7qzodWG"
      },
      "outputs": [],
      "source": [
        "documents = chunked_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9I8isKXog_P"
      },
      "outputs": [],
      "source": [
        "document_embeddings = embeddings_model.encode(documents, convert_to_tensor=True).cpu().numpy()\n",
        "document_embeddings = np.array(document_embeddings).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXVeGozWokd5"
      },
      "outputs": [],
      "source": [
        "dimension = document_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(document_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO6aOCbwonfu"
      },
      "outputs": [],
      "source": [
        "class SimpleRetriever:\n",
        "    def __init__(self, index, documents: List[str]):\n",
        "        self.index = index\n",
        "        self.documents = documents\n",
        "        self.embeddings_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "    def retrieve(self, query: str, top_k: int = 3) -> List[str]:\n",
        "        query_embedding = self.embeddings_model.encode([query], convert_to_tensor=True).cpu().numpy().astype('float32')\n",
        "        _, indices = self.index.search(query_embedding, top_k)\n",
        "        return [self.documents[i] for i in indices[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaLxd2-2os09"
      },
      "outputs": [],
      "source": [
        "class LLMWrapper:\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def invoke(self, prompt: str, input_len) -> str:\n",
        "        try:\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", max_length=input_len, truncation=True)\n",
        "            prompt_length = inputs.input_ids.shape[1]\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens = 100,\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "            generated_tokens = outputs[0][prompt_length:]\n",
        "            decoded_output = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "            return decoded_output\n",
        "\n",
        "        except IndexError as e:\n",
        "            print(f\"IndexError occurred: {str(e)}\")\n",
        "            print(\"This error typically occurs when input sequence length exceeds model's position embedding limit\")\n",
        "            return \"Error generating response - input may be too long\"\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error occurred: {str(e)}\")\n",
        "            return \"Error generating response\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrZNigHKpEGg"
      },
      "outputs": [],
      "source": [
        "class SimpleRAG:\n",
        "    def __init__(self, llm, retriever):\n",
        "        self.llm = llm\n",
        "        self.retriever = retriever\n",
        "\n",
        "#     def generate(self, query: str) -> str:\n",
        "#         retrieved_docs = self.retriever.retrieve(query)\n",
        "#         augmented_query = f\"{retrieved_docs} Question: {query}\\nAnswer:\"\n",
        "#         response = self.llm.invoke(augmented_query)\n",
        "#         return response\n",
        "    def generate(self, query: str) -> str:\n",
        "        docs = self.retriever.retrieve(query)\n",
        "        joined_docs = \" \".join(docs)\n",
        "        #7000 for Pythia, 3000 for gpt-2\n",
        "        shortened_docs = joined_docs[:3000]\n",
        "\n",
        "        prompt = f\"\"\"Use the following information to help answer the question,\n",
        "    but respond in your own words without quoting the sources directly: {shortened_docs}.\n",
        "    Make sure your answer is true according to the provided information.\n",
        "    Think carefully about your answer and make it concise but fully answer the question.\n",
        "    Question: {query}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "        response = self.llm.invoke(prompt = prompt, input_len = len(prompt))\n",
        "        return response\n",
        "# Make sure your answer is true according to the provided information.\n",
        "# Think carefully about your answer and make it concise but fully answer the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPLi2MbfpG_6"
      },
      "outputs": [],
      "source": [
        "retriever = SimpleRetriever(index, documents)\n",
        "llm = LLMWrapper(model, tokenizer)  # Using your existing model and tokenizer\n",
        "rag = SimpleRAG(llm, retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtHLdcG4SvUz",
        "outputId": "fcb27c42-4ea6-48ae-ff5c-57efc096e601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Precision agriculture uses precise seed production to produce precision genotypes with improved growth and performance traits. It produces seeds with greater seed vigour but lower seed moisture, and is cheaper than other technologies when compared to in-field seed production.\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the primary benefit of precision agriculture?\"\n",
        "response = rag.generate(query)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6jTSJjWSvUz",
        "outputId": "7979ada0-c853-4261-8f78-59defd28e77c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'stop' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stop\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
          ]
        }
      ],
      "source": [
        "#stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iHy8nELSvUz"
      },
      "outputs": [],
      "source": [
        "def run_query(query):\n",
        "    print(query)\n",
        "    print('\\n')\n",
        "    response = rag.generate(query)\n",
        "    print(response)\n",
        "    print('\\n')\n",
        "    print('-----------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OmE4r6MSvUz"
      },
      "outputs": [],
      "source": [
        "question_set = [\"What is the primary benefit of precision agriculture?\",\n",
        "\"What is a black hole?\",\n",
        "\"What is the role of ribosomes in a cell?\",\n",
        "\"What is the significance of the periodic table in chemistry?\",\n",
        "\"What is the function of an algorithm in computer science?\",\n",
        "\"What causes volcanic eruptions?\",\n",
        "\"What is the difference between civil and mechanical engineering?\",\n",
        "\"What is the concept of 'alloying' in materials science?\",\n",
        "\"What is the Pythagorean theorem?\",\n",
        "\"What is the function of white blood cells in the immune system?\",\n",
        "\"How does crop rotation benefit soil health?\",\n",
        "\"What is the Hubble Space Telescope used for?\",\n",
        "\"What is the function of mitochondria in cells?\",\n",
        "\"What is an ionic bond?\",\n",
        "\"What is machine learning?\",\n",
        "\"What are the three main types of rocks in the rock cycle?\",\n",
        "\"What is the principle behind hydraulic systems?\",\n",
        "\"What is the purpose of heat treatment in materials science?\",\n",
        "\"What is a derivative in calculus?\",\n",
        "\"What is the difference between a virus and a bacterium?\",\n",
        "\"What is sustainable farming?\",\n",
        "\"What is the concept of the 'Big Bang'?\",\n",
        "\"What is photosynthesis?\",\n",
        "\"What is the role of catalysts in chemical reactions?\",\n",
        "\"What is the difference between a compiler and an interpreter?\",\n",
        "\"What is the difference between weather and climate?\",\n",
        "\"What is an electrical circuit?\",\n",
        "\"What is the concept of nanotechnology?\",\n",
        "\"What is the difference between an exothermic and endothermic reaction?\",\n",
        "\"What is the difference between supervised and unsupervised learning in machine learning?\",\n",
        "\"What causes earthquakes?\",\n",
        "\"What is the difference between AC and DC in electrical engineering?\",\n",
        "\"What is the role of polymers in materials science?\",\n",
        "\"What is a matrix and how is it used in mathematics?\",\n",
        "\"What is the function of the liver in the human body?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhX5X9YGSvU0"
      },
      "outputs": [],
      "source": [
        "for question in question_set:\n",
        "    run_query(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjTvEAv9SvU0"
      },
      "outputs": [],
      "source": [
        "# def tokenize_qa(examples):\n",
        "# #     q_encodings = tokenizer(\n",
        "# #         examples['q'],\n",
        "# #         truncation=True,\n",
        "# #         padding='max_length',\n",
        "# #         max_length=64,\n",
        "# #         return_tensors=None\n",
        "# #     )\n",
        "\n",
        "#     a_encodings = tokenizer(\n",
        "#         examples['a'],\n",
        "#         truncation=True,\n",
        "#         padding='max_length',\n",
        "#         max_length=64,\n",
        "#         return_tensors=None\n",
        "#     )\n",
        "#     return {\n",
        "# #         'input_ids': q_encodings['input_ids'],\n",
        "# #         'attention_mask': q_encodings['attention_mask']\n",
        "#         'input_ids': a_encodings['input_ids'],\n",
        "#         'attention_mask': a_encodings['attention_mask']\n",
        "#     }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJYtb6HpSvU0"
      },
      "outputs": [],
      "source": [
        "# tokenized_dataset = finetuning_dataset.map(\n",
        "#     tokenize_qa,\n",
        "#     batched=True,\n",
        "#     remove_columns=finetuning_dataset.column_names\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xNDsDAvSvU0"
      },
      "outputs": [],
      "source": [
        "# q_tokenized = finetuning_dataset.map(\n",
        "#     lambda x: tokenizer(x['q'], truncation=True, padding=\"max_length\", max_length=64, return_tensors=None),\n",
        "#     batched=True\n",
        "# )\n",
        "# a_tokenized = finetuning_dataset.map(\n",
        "#     lambda x: tokenizer(x['a'], truncation=True, padding=\"max_length\", max_length=64, return_tensors=None),\n",
        "#     batched=True\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}